
## 1. Essential Matrix 为什么纯旋转退化
- 定义：**E = [t]× R**
- 纯旋转：t = 0 ⇒ [t]× = 0 ⇒ **E = 0**
- 对极约束：x₂ᵀ E x₁ = 0 恒成立 ⇒ **不提供任何约束**
- 直觉：无基线、无视差（parallax）⇒ 平移与深度不可恢复

---

## 2. Homography H 能不能恢复平移
### 2.1 适用条件
- **纯旋转** 或 **场景点共面（单一平面）**
- 非平面 3D 场景存在视差 ⇒ 单一 H 无法同时拟合所有点

### 2.2 平面场景下的形式
- 平面：H = R + (t nᵀ) / d  
  - n：平面法向（单位向量）
  - d：平面到相机距离

### 2.3 能恢复到什么程度
- H **包含**平移项，但平移与 (n, d) 耦合：
  - 只能得到 **t/d** 这类“比例量”
  - **尺度不定**（单目固有问题）
  - 通常 **多解**（分解得到多组 (R, t, n) 候选）
- 若额外已知：
  - **平面法向 n**（例如地面法向已知），或
  - **尺度/距离 d**（双目/RGB-D/标定板尺寸）
  ⇒ 才可能更确定地恢复 t（至少方向更稳，带尺度时可恢复真实大小）

---

## 3. “旋转矩阵对加法不封闭”是什么意思
- 旋转矩阵集合：SO(3) = { R | RᵀR = I, det(R)=1 }
- “对加法不封闭”：
  - R₁, R₂ ∈ SO(3) 但 **R₁ + R₂ 通常不满足 RᵀR=I**
- “对乘法封闭”：
  - R₁R₂ 仍是旋转矩阵（旋转的组合方式）

---

## 4. 为什么使用李代数（SO(3)/SE(3) 的优化核心）
### 4.1 根因：旋转在流形上，不是线性空间
- GN/LM 的更新形式在欧氏空间是：x ← x + Δx
- 旋转矩阵不能直接做 R + ΔR（会破坏正交约束）

### 4.2 做法：在切空间“加”，回到群上“乘”
- 用李代数最小参数：δφ ∈ ℝ³
- 指数映射：RΔ = Exp(δφ^)  
- 乘法更新（保持合法旋转）：
  - **R ← Exp(δφ^) · R**（左乘形式常见）

### 4.3 为什么不直接“乘”就完了
- “乘法更新”是对的，但优化器需要解的是 **可加的增量向量**
- 李代数提供：
  - 最小自由度（3维）
  - 无约束优化
  - 数值稳定的局部线性化

---

## 5. GN 为什么可能不收敛：H 奇异/病态的真实含义
### 5.1 GN 线性化与增量方程
- 目标：min ||r(x)||²
- 线性化：r(x+Δx) ≈ r + JΔx
- 正规方程：**HΔx = g**
  - H = JᵀJ
  - g = -Jᵀr

### 5.2 H 奇异（不可逆）
- det(H)=0 或存在 λ_min=0
- 意味着存在方向 v：
  - Jv = 0 ⇒ 沿 v 改变状态，测量不变 ⇒ **该方向不可观**
- 结果：Δx 无唯一解或根本求不出

####  奇异矩阵（Singular Matrix）的等价条件

- 设 A 是一个 n×n 的方阵，以下条件完全等价：
	1. **A 不可逆**
	   - A 的逆矩阵不存在
	
	1. **行列式为 0**
	   - det(A) = 0
	
	1. **存在 0 特征值**
	   - A 至少有一个特征值等于 0
	
	1. **存在非零零空间向量**
	   - 存在 v ≠ 0，使得 A v = 0
	
	1. **秩不满（秩亏）**
	   - rank(A) < n
	
	1. **线性方程组无唯一解**
	   - Ax = b 可能无解或有无穷多解，而不会有唯一解

>A 是奇异矩阵  
  <=> det(A)=0  
  <=> A 有 0 特征值  
  <=> A 不可逆  
  <=> 存在非零 v 使得 Av=0

### 5.3 H 病态（条件数巨大）
- cond(H)=λ_max/λ_min ≫ 1
- 极弱方向会被数值放大：
  - Δx 可能过大、方向不可靠
  - 线性化假设失效（步长太大）⇒ 代价反而上升、震荡或发散

---

## 6. LM 为什么更稳：它解决什么、不解决什么
### 6.1 LM 的改动
- **(H + λI) Δx = g**
- λ>0 ⇒ H+λI 一定可逆（即使 H 奇异）

### 6.2 LM 的效果
- 抬升小特征值 ⇒ 改善条件数 ⇒ 控制步长
- λ 很大时近似最速下降：
  - Δx ≈ (1/λ) g（慢但稳）

### 6.3 LM 的边界
- LM 能解决 **数值不可逆/病态**（让方程可解、稳定下降）
- LM 不能“创造观测”：
  - 若某方向本质不可观（结构性退化），LM 只是正则化压住漂移
  - 真正让其可观需额外信息/传感器或运动激励

---

## 7. 边缘化（Marginalization）在滑窗中的作用
### 7.1 为什么要边缘化
- 滑窗只保留最近 N 帧以控制计算量
- 直接删老帧会丢掉大量约束信息

### 7.2 边缘化做了什么
- 将要删除变量 xm 消去，把其对保留变量 xr 的影响压缩成 **先验 prior**
- 常用 Schur Complement 得到新的 prior：
  - H_prior = H_rr - H_rm H_mm⁻¹ H_mr
- 结果：**删变量但不删信息**

### 7.3 边缘化并不是非线性优化，为什么有ceres因子


边缘化本身确实是 Schur 消元，是确定性的。但边缘化的**结果**需要被"包装"成一个 Ceres Factor，才能在后续优化中继续约束保留的变量。

### 让我解释这个转换过程

**边缘化产生的是什么？**

```
Schur 补后得到：
- 新的 Hessian：A' = Arr - Arm * Amm⁻¹ * Amr
- 新的信息向量：b' = brr - Arm * Amm⁻¹ * bmm

这等价于一个二次型约束：
  ½ xᵀ A' x - bᵀ x = const
```

**问题来了**：Ceres 需要的是什么？

```
Ceres 需要：
- 残差 r（向量）
- 雅可比 J（矩阵）

然后 Ceres 内部会构建：
  A = Jᵀ J
  b = Jᵀ r
```

**所以需要做一个"逆向分解"**：

```
已知：A', b'（边缘化的结果）
求：J, r 使得 Jᵀ J = A', Jᵀ r = b'
```

### 代码中的实现

```cpp
void MarginalizationInfo::marginalize() {
    // ... Schur 补得到 A 和 b ...
    
    // 关键：把 A, b 分解回 J, r 的形式
    // A = V * S * Vᵀ（特征值分解）
    Eigen::SelfAdjointEigenSolver<Eigen::MatrixXd> saes2(A);
    
    // J = sqrt(S) * Vᵀ
    // 这样 Jᵀ J = V * sqrt(S) * sqrt(S) * Vᵀ = V * S * Vᵀ = A ✓
    linearized_jacobians = S_sqrt.asDiagonal() * saes2.eigenvectors().transpose();
    
    // r = sqrt(S⁻¹) * Vᵀ * b
    // 这样 Jᵀ r = V * sqrt(S) * sqrt(S⁻¹) * Vᵀ * b = V * Vᵀ * b = b ✓
    linearized_residuals = S_inv_sqrt.asDiagonal() * saes2.eigenvectors().transpose() * b;
}
```

### 为什么要这样做？

```
┌─────────────────────────────────────────────────────────┐
│  边缘化的数学本质：                                      │
│                                                         │
│  原问题：min ½||r_imu||² + ½||r_vis||² + ...           │
│                                                         │
│  边缘化后：min ½||r_imu'||² + ½||r_vis'||² + ½||r_prior||²  │
│                                        ↑                │
│                              这就是边缘化先验因子        │
│                              它"压缩"了被边缘化变量的信息 │
└─────────────────────────────────────────────────────────┘
```

### MarginalizationFactor 的 Evaluate

```cpp
bool MarginalizationFactor::Evaluate(...) {
    // 计算当前状态相对于线性化点的增量
    Eigen::VectorXd dx = x_current - x_linearization_point;
    
    // 一阶泰勒展开：r = r₀ + J₀ * dx
    residuals = linearized_residuals + linearized_jacobians * dx;
    
    // 雅可比保持固定（FEJ）
    jacobians = linearized_jacobians;
    
    return true;
}
```

### 图示总结

```
边缘化过程：
┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│  原始因子    │     │  Schur 补    │     │  Ceres Factor│
│  (IMU,视觉)  │ ──► │  得到 A', b' │ ──► │  J, r 形式   │
│              │     │              │     │              │
└──────────────┘     └──────────────┘     └──────────────┘
                           ↓
                     确定性计算
                     （不是优化）
                           ↓
                     ┌──────────────┐
                     │ 分解：       │
                     │ A' = JᵀJ    │
                     │ b' = Jᵀr    │
                     └──────────────┘
```

### 本质理解

|概念|说明|
|---|---|
|边缘化|确定性的 Schur 消元，压缩信息|
|边缘化先验因子|把压缩后的信息"包装"成 Ceres 能理解的 (J, r) 形式|
|为什么要包装|Ceres 的接口是 CostFunction，需要提供残差和雅可比|

**简单说**：边缘化是"压缩信息"，MarginalizationFactor 是"把压缩后的信息翻译成 Ceres 的语言"。


## 8. FEJ（First Estimate Jacobian）与一致性/可观性

> **人话解释**：
>  x0 被边缘化之后，虽然该状态变量从滑窗中删除，但它所包含的观测信息会以 **先验（prior）因子** 的形式保留下来，并作用在仍然保留的变量上，例如后续帧的位姿 x1 以及与 x0 共视的特征约束等。这些变量本身并没有被边缘化，但它们已经受到边缘化先验的约束。
> 
   在后续迭代优化过程中，x1 和相关特征点的状态会不断更新，如果对这些旧约束重新再线性化，就会得到新的 Jacobian。然而，由于 prior 是在边缘化时刻的线性化点构建的，并且在边缘化后无法再重新线性化更新，因此这些与 prior 直接相关的旧因子也需要保持 Jacobian 的一致性，继续使用边缘化时刻的线性化点（FEJ）。
   >
   否则，如果对这些变量使用新的线性化点重新计算 Jacobian，就会导致 prior 与其他因子的零空间结构不一致，从而在本应不可观的方向上引入虚假约束，破坏系统一致性。
>
  而对于那些不受 prior 影响的新观测因子，则可以正常在当前估计点重新线性化，使用最新的 Jacobian。
  
### 8.1 问题：反复线性化会改变“零空间”
- 非线性系统每次迭代都会在新估计点计算 Jacobian：J(x_k)
- 线性化点变了 ⇒ J 变 ⇒ H=JᵀJ 的零空间结构也变
- 影响：原本不可观的自由度可能被“假约束”，导致 **过度自信（协方差虚假收缩）**

### 8.2 FEJ 的做法
- 对某些因子（尤其边缘化 prior、旧观测）：
  - Jacobian 固定在 **第一次估计点**：J(x_first)
- 目的：保持不可观方向的正确零空间 ⇒ 提升 **一致性**

### 8.3 一致性 vs 可观性
- 可观性：某状态方向变化是否会引起测量变化；不引起 ⇒ 不可观
	 - 通俗的讲：有两个一模一样的房子， 他们在地球上的位置不一样，  朝向不一样，  我的观测系统并不能区分出我在那个房子，也就是xyz，yaw不可观。
	- 但是如果其中一个房子是躺着的，那观测系统是能区分出来，因为重力方向可观。
- 一致性：估计误差与系统给出的协方差匹配；不可观被假约束 ⇒ 协方差过小 ⇒ 不一致

---

## 9. 工程常用结论（可直接用来判断问题）
- **纯旋转**：
  - E 退化；应更依赖 H/旋转估计；VIO 平移/深度会差
- **平面/弱视差**：
  - H 拟合好但无法可靠恢复 3D 深度；易退化
- **cond(H) 巨大（如 1e12）**：
  - 强烈病态或退化方向存在；必须 LM/正则化/改运动激励/加观测
- **LM 对奇异 H 仍有效（数值上）**：
  - 但不可观方向不会因 LM 变可观；需要外部信息或约束（GNSS/磁力计/双目/深度等）