![[LM优化.png]]

## 非线性最小二乘优化：正规方程与 LM 阻尼

### 1. 优化目标（残差平方和）

给定残差向量 \(r(x)\)，优化目标为：

$$
\min_x f(x),\qquad 
f(x)=\frac12\|r(x)\|^2=\frac12\sum_i r_i(x)^2
$$

---

### 2. 线性化：把非线性问题变成局部线性

在当前点 \(x\) 附近做一阶泰勒展开：

$$
r(x+\Delta x)\approx r(x)+J\Delta x
$$

其中 \(J=\frac{\partial r}{\partial x}\) 是雅可比矩阵。

于是每一步迭代变为求：

$$
\min_{\Delta x}\|r+J\Delta x\|^2
$$

目标是让线性化后的残差 \(r+J\Delta x\) 尽可能小。

---

### 3. 正规方程（Gauss-Newton）

对上式求导并令导数为 0，得到正规方程：

$$
J^\top J\,\Delta x=-J^\top r
$$

定义：

$$
H=J^\top J,\qquad g=-J^\top r
$$

则：

$$
H\Delta x=g
$$

解出的 \(\Delta x\) 是当前线性近似下使残差最小的最优更新步。

---

### 4. LM 方法：加入阻尼项 \(\lambda\)

当线性化不可靠或步子过大时，引入阻尼：

$$
(J^\top J+\lambda I)\Delta x=-J^\top r
$$

- \(\lambda\) 小 → 更像 Gauss-Newton（步大，收敛快）
- \(\lambda\) 大 → 更像梯度下降（步小，更稳定）

---

### 5. \(\lambda\) 如何调整？

依据本次更新是否让代价下降：

#### ✅ 若代价下降（step 成功）

$$
F(x+\Delta x)<F(x)
$$

说明模型可信 → 可以更激进：

$$
\lambda \leftarrow \lambda/\nu
$$

#### ❌ 若代价上升（step 失败）

$$
F(x+\Delta x)\ge F(x)
$$

说明步太大或方向不准 → 更保守：

$$
\lambda \leftarrow \lambda\cdot\nu
$$

---

### 核心一句话

> 每次迭代都在最小化 \(r+J\Delta x\)，  
> 正规方程给出最优增量 \(\Delta x\)，  
> LM 的 \(\lambda\) 用来控制步长：成功则减小，失败则增大。